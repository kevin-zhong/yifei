perl -i -p -e "s/\d+:\d+:\d+//g"

[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from ProcTestor
[ RUN      ] ProcTestor.ShareMem
child process_3, pid=16840
child process_4, pid=16841
child process_5, pid=16842
child process_6, pid=16843
child process_6 end, pid=16843
2012/08/03  402 [./ppc/yf_signal.c:81][alert][16836#3959637088]: empty_child_proc 16839 exited on signal 11
2012/08/03  402 [./ppc/yf_signal.c:91][notice][16836#3959637088]: child_process 16843 exited with code 0
2012/08/03  402 [yf_proc_testor.cpp:270][debug][16836#3959637088]: exit child process = 1
child process_4 end, pid=16841
2012/08/03  402 [./ppc/yf_signal.c:91][notice][16836#3959637088]: child_process 16841 exited with code 0
2012/08/03  402 [yf_proc_testor.cpp:270][debug][16836#3959637088]: exit child process = 2
child process_5 end, pid=16842
2012/08/03  402 [./ppc/yf_signal.c:91][notice][16836#3959637088]: child_process 16842 exited with code 0
2012/08/03  402 [yf_proc_testor.cpp:270][debug][16836#3959637088]: exit child process = 3
child process_3 end, pid=16840
2012/08/03  402 [./ppc/yf_signal.c:91][notice][16836#3959637088]: child_process 16840 exited with code 0
2012/08/03  402 [yf_proc_testor.cpp:270][debug][16836#3959637088]: exit child process = 4
last cnt=1584032
2012/08/03  402 [./ppc/yf_signal.c:124][alert][16836#3959637088]: kill(16839, 1) failed (3: No such process)
2012/08/03  402 [./ppc/yf_signal.c:124][alert][16836#3959637088]: kill(16839, 28) failed (3: No such process)
2012/08/03  402 [./ppc/yf_signal.c:124][alert][16836#3959637088]: kill(16839, 3) failed (3: No such process)
2012/08/03  402 [./ppc/yf_signal.c:91][notice][16836#3959637088]: test_channel_func 16837 exited with code 0
2012/08/03  402 [yf_proc_testor.cpp:320][debug][16836#3959637088]: exit child process = 1
2012/08/03  402 [./ppc/yf_signal.c:91][notice][16836#3959637088]: test_channel_func 16838 exited with code 0
2012/08/03  402 [yf_proc_testor.cpp:320][debug][16836#3959637088]: exit child process = 2


忘了设置 tm evt，导致一个子command退出后，timer还是保留下来了，但是也没造成什么大的问题，留下了一个警告而已；
12/08/07  017 [./mio_driver/event_in/yf_tm_event_in.c:213][debug][7153#3777741920]: single timer out, stm evt num=5, near evt num=6, addr=000000001D3B9990
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:335][warn][7153#3777741920]: cat execute timeout
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:114][warn][7153#3777741920]: yf_proc no proc (000000001D3B9E50) 
12/08/07  017 [./mio_driver/event_in/yf_tm_event_in.c:213][debug][7153#3777741920]: single timer out, stm evt num=4, near evt num=5, addr=000000001D3B99E0
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:335][warn][7153#3777741920]: ./exe_ctx/echo.py execute timeout
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:114][warn][7153#3777741920]: yf_proc no proc (000000001D3B9F10) 
12/08/07  017 [./mio_driver/event_in/yf_tm_event_in.c:213][debug][7153#3777741920]: single timer out, stm evt num=3, near evt num=4, addr=000000001D3B9A30
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:335][warn][7153#3777741920]: sleep execute timeout
12/08/07  017 [./mio_driver/event_in/yf_fd_event_in.c:149][error][7153#3777741920]: fd=10 not in use, evts_capcity=128
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:129][debug][7153#3777741920]: destory detach process, kill (7157, 9) success
12/08/07  017 [./mio_driver/event_in/yf_tm_event_in.c:213][debug][7153#3777741920]: single timer out, stm evt num=2, near evt num=3, addr=000000001D3B9A80
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:335][warn][7153#3777741920]: uname execute timeout
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:114][warn][7153#3777741920]: yf_proc no proc (000000001D3BA090) 
12/08/07  017 [./mio_driver/event_in/yf_tm_event_in.c:213][debug][7153#3777741920]: single timer out, stm evt num=1, near evt num=2, addr=000000001D3B9AD0
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:335][warn][7153#3777741920]: sleep execute timeout
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:114][warn][7153#3777741920]: yf_proc no proc (000000001D3BA150) 
12/08/07  017 [./mio_driver/event_in/yf_tm_event_in.c:213][debug][7153#3777741920]: single timer out, stm evt num=0, near evt num=1, addr=000000001D3B9B20
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:335][warn][7153#3777741920]: ./exe_ctx/test_unexsit execute timeout
12/08/07  017 [./mio_driver/event_in/yf_processor_event_in.c:114][warn][7153#3777741920]: yf_proc no proc (000000001D3BA210) 


epoll 和其他多路复用（select，poll）驱动函数相比有很多奇特的地方：
1，如果监控 fd 为空，会报错（invalid args）
2，后来为了避开上面这个问题（有时候是没有fd，比如只想测试 timers）尝试将 stdout 的读加入进去，
		竟然报错了（不准干啊!!应该是 epoll 判断了只有socket类型的句柄才能加入，其他如终端的fd是被禁止的）
12/08/08  904 [./mio_driver/event_in/yf_fd_event_in.c:132][debug][19333#2206712896]: alloc fd evt, fd=1
12/08/08  904 [./mio_driver/fd_poller/yf_epoll.c:140][debug][19333#2206712896]: epoll add event: fd:1 ev:1, other polled=0
12/08/08  904 [./mio_driver/fd_poller/yf_epoll.c:158][error][19333#2206712896]: epoll ctl fd failed, fd=1 (1: Operation not permitted)
12/08/08  904 [./mio_driver/event_in/yf_fd_event_in.c:206][error][19333#2206712896]: fd=1, evt=read_evt activate poll failed
yf_driver_testor.cpp:142: Failure

只能用 socketpair 创建了一对channel，然后将其中一个加入了读事件监控；



epoll 的超时（其实是所有的系统定时机制）都是不精确，以及不可预测的
1，精度是有限的，比如有的系统只能精确到 10ms；我测试用的系统基本可以精确到2ms以内
2，不可预测性非常大，比如epoll超时为 104ms，但实际上过了 481*4=1924ms 才退出
		这应该和系统的调度相关的，系统的调度导致有时候一个进程过1，2s才能被再次放入cpu调度；
		所以出现这种1-2s的误差是没法避免的；
3，但可以确定的是，像2这种误差只会出现延迟，而不会提前1-2s到来，即可以保证定时器最后耗的时间只会比预期的长，不会短；
4，从上面这条可以看出，误差在1-3s估计是很难避免的，所以如果请求回包的超时设置为3-4s感觉没太大意义；
		
12/08/08  403 [./mio_driver/fd_poller/yf_epoll.c:183][debug][19639#1361224768]: epoll timer: 104
12/08/08  403 [./mio_driver/fd_poller/yf_epoll.c:191][debug][19639#1361224768]: epoll ready 0 of 1
12/08/08  403 [./mio_driver/fd_poller/yf_epoll.c:210][debug][19639#1361224768]: epoll() returned no events with timeout
12/08/08  331 [./mio_driver/event_in/yf_tm_event_in.c:363][debug][19639#1361224768]: prev near tm index=22, poll timer after
 periods=481, tm period cnt=31833
12/08/08  331 [./mio_driver/event_in/yf_tm_event_in.c:386][debug][19639#1361224768]: [0][0]=2181038080
12/08/08  331 [./mio_driver/event_in/yf_tm_event_in.c:267][debug][19639#1361224768]: near tm roll index=22, check index_it=4
7
12/08/08  331 [./mio_driver/event_in/yf_tm_event_in.c:221][debug][19639#1361224768]: single timer out, stm evt num=2275, nea
r evt num=4, addr=00002B295139E100
12/08/08  331 [yf_driver_testor.cpp:53][debug][19639#1361224768]: real=127336 vs target=125512, big lacy diff=1824
12/08/08  331 [./mio_driver/event_in/yf_tm_event_in.c:267][debug][19639#1361224768]: near tm roll index=22, check index_it=5
3
12/08/08  331 [./mio_driver/event_in/yf_tm_event_in.c:221][debug][19639#1361224768]: single timer out, stm evt num=2274, nea
r evt num=3, addr=00002B29513BCD80
12/08/08  331 [yf_driver_testor.cpp:53][debug][19639#1361224768]: real=127336 vs target=125536, big lacy diff=1800




12/08/21 19:03:51 633
	对 evt driver 和子进程一起做单元测试，为了方便，直接在父进程中先初始化了 evt driver，
其中用的内核事件驱动为 epoll；设想中的子进程在分离后，会产生一份新的epoll驱动；然而却出现了完全
意想不到的事情，看日志：
点击(此处)折叠或打开

[4206#2053186656]: epoll add event: fd:6 ev:1
[4205#2053186656]: epoll add event: fd:5 ev:1
[4206#2053186656]: epoll: 0: fd:6 rev:0001
[4206#2053186656]: epoll: 0: fd:5 rev:0001
	日志中的第一个数字为进程号，明显：4205为父进程，4206为子进程；父进程在epoll中监控了fd=5
子进程监控了fd=6；第三行日志为子进程关注的fd=6有数据，正常现象；第四行，竟然出现了一个没注册过
的fd=5事件出来了；epoll事件中的data指向了一个未初始化的地方（实际上是父进程的一个初始化过的
结构）；于是崩溃了；

	了解了，epoll 是能被子进程继承的，且父子会公用一份内核变量，共享了epoll的所有数据；自然
悲剧了...
	
	于是，如果需要父子进程都需要epoll，一定要分别初始化....
	

task 发送给子进程，子进程会判断时间差，结果出现了问题，时间跨度竟然变成了负值；
发现是自己为了避免频繁调用gettimeofday对时间值进行了cache造成的；
查了下 gettimeofday，发现这个调用其实代价不高；还是每次调用得了；
http://blog.csdn.net/russell_tao/article/details/7185588



13/02/23 22:52
多线程编程真的非常容易出问题，昨天晚上发现了子线程创建后先于父线程运行导致的bug；
今天发现这里还有bug：
创建的子线程的id号非常偶尔的情况下不是递增的，导致child no前后变化...；
[kevin_zhong@localhost test]$ grep "thread is created" dir/bridge.log 
13/02/23 12:58:16 894 [./ppc/yf_thread.c:68][debug][4326#3086718672]: thread is created: 3068599184
13/02/23 12:58:16 894 [./ppc/yf_thread.c:68][debug][4326#3086718672]: thread is created: 3067546512
13/02/23 12:58:16 894 [./ppc/yf_thread.c:68][debug][4326#3086718672]: thread is created: 3066493840
13/02/23 12:58:16 894 [./ppc/yf_thread.c:68][debug][4326#3086718672]: thread is created: 3065441168

13/02/25 19:47
今天测试 bridge 的时候，发现有一个task回包无缘无故丢失了，导致测试程序一直不能
正常退出，最后根据日志发现了问题，原来子线程回复的时候，push task 到 task queue 
里面因为容量不足失败了，而子线程现在没有重试，直接就返回；父线程又没有加任何检测
手段，自然只能一直等待这个已经丢失永远不可能到达的回包；解决办法，简单的是让子线程
循环不停永远重试，直到task queue有足够的空间，最后将回包压入queue；这一方法对于
线程来说是没问题的；但其实这一问题对于子进程模式来说，是有问题的，假如子线程core掉
然后这个task就丢失了；所以彻底的解决办法是父线程/进程自己加上检测手段，加入定时器
即可；
